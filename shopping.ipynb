{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e2fded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "TEST_SIZE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df53ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "  \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df['Month'] = encoder.fit_transform(df['Month'])\n",
    "    df['VisitorType'] = (df['VisitorType'] == 'Returning_Visitor').astype(int)\n",
    "    df['Weekend'] = df['Weekend'].astype(int)\n",
    "\n",
    "    labels = df['Revenue'].astype(int)\n",
    "    evidence = df.drop('Revenue', axis=1)\n",
    "\n",
    "    return evidence, labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "448e1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(evidence, labels, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Balance the classes in the dataset by oversampling the minority class.\n",
    "\n",
    "    Returns a tuple (balanced_evidence, balanced_labels).\n",
    "    \"\"\"\n",
    "    # Combine evidence and labels into a single DataFrame\n",
    "    data = evidence.copy()\n",
    "    data['Label'] = labels\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    majority_class = data[data['Label'] == 0]\n",
    "    minority_class = data[data['Label'] == 1]\n",
    "\n",
    "    # Undersample majority class (old approach - now using oversampling)\n",
    "    # Oversample minority class\n",
    "    minority_class_oversampled = minority_class.sample(n=round((1-alpha)*len(majority_class)), replace=True, random_state=42)\n",
    "\n",
    "    # Combine majority class with oversampled minority class\n",
    "    balanced_data = pd.concat([majority_class, minority_class_oversampled])\n",
    "\n",
    "    # Shuffle the balanced dataset\n",
    "    balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Separate evidence and labels\n",
    "    balanced_labels = balanced_data['Label']\n",
    "    balanced_evidence = balanced_data.drop('Label', axis=1)\n",
    "\n",
    "    return balanced_evidence, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eda980cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', StandardScaler(), [ 'Administrative_Duration',\n",
    "                                            'Informational_Duration',\n",
    "                                            'ProductRelated',\n",
    "                                            'ProductRelated_Duration',\n",
    "                                            'PageValues'\n",
    "                                                                                    ])\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f2f76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline():\n",
    "    preprocessor = preprocess_data()\n",
    "    knn_pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', KNeighborsClassifier()),\n",
    "    ])\n",
    "\n",
    "    # Add class_weight='balanced' to handle imbalanced data\n",
    "    logreg_pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor), \n",
    "\n",
    "            # it changes the decision boundary to account for class imbalance\n",
    "            #penlize mistakes on the minority class more heavily\n",
    "            # Without balanced weights (default):\n",
    "            # weight_class_0 = 1.0\n",
    "            # weight_class_1 = 1.0\n",
    "            # # With balanced weights:\n",
    "            # weight_class_0 = total_samples / (2 * count_class_0)  = 0.588\n",
    "            # weight_class_1 = total_samples / (2 * count_class_1)   = 3.333 \n",
    "            ('logistic', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "        ]\n",
    "    )\n",
    "    return knn_pipe, logreg_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "899a83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_with_gridsearch(knn_pipe: Pipeline, logreg_pipe: Pipeline, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Full GridSearchCV over k, weights, and metric for KNN, and C for LogisticRegression.\n",
    "    We use 'balanced_accuracy' to reflect sensitivity/specificity balance.\n",
    "    \"\"\"\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    }\n",
    "    param_grid_logreg = {\n",
    "        'logistic__C': [0.01, 0.1, 1, 10, 100],\n",
    "    }\n",
    "    \n",
    "    grid_search_knn = GridSearchCV(knn_pipe, param_grid_knn, cv=5, scoring='balanced_accuracy')\n",
    "    grid_search_logreg = GridSearchCV(logreg_pipe, param_grid_logreg, cv=5, scoring='balanced_accuracy')\n",
    "\n",
    "    return grid_search_knn, grid_search_logreg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eed88b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(evidence, labels):\n",
    "    \"\"\"\n",
    "    Given a list of evidence lists and a list of labels, return\n",
    "    fitted KNN and LogisticRegression models trained on the data.\n",
    "    \"\"\"\n",
    "    knn_pipe, logreg_pipe = pipline()\n",
    "    \n",
    "    # Define parameter grid including alpha values for balancing\n",
    "    param_grid_knn = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'classifier__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    }\n",
    "    param_grid_logreg = {\n",
    "        'logistic__C': [0.01, 0.1, 1, 10, 100],\n",
    "    }\n",
    "    \n",
    "    # Alpha values to try for balancing (0 = fully balanced, higher = more minority bias)\n",
    "    alpha_values = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "    \n",
    "    best_score = -1\n",
    "    best_alpha = None\n",
    "    best_knn_model = None\n",
    "    \n",
    "    # Try each alpha value\n",
    "    for alpha in alpha_values:\n",
    "        balanced_evidence, balanced_labels = balance_classes(evidence, labels, alpha=alpha)\n",
    "        grid_search_knn = GridSearchCV(knn_pipe, param_grid_knn, cv=5, scoring='balanced_accuracy')\n",
    "        grid_search_knn.fit(balanced_evidence, balanced_labels)\n",
    "        \n",
    "        if grid_search_knn.best_score_ > best_score:\n",
    "            best_score = grid_search_knn.best_score_\n",
    "            best_alpha = alpha\n",
    "            best_knn_model = grid_search_knn.best_estimator_\n",
    "    \n",
    "    print(f\"Best alpha for KNN: {best_alpha} (CV score: {best_score:.4f})\")\n",
    "    \n",
    "    # Train logistic regression without balancing\n",
    "    grid_search_logreg = GridSearchCV(logreg_pipe, param_grid_logreg, cv=5, scoring='balanced_accuracy')\n",
    "    grid_search_logreg.fit(evidence, labels)\n",
    "    \n",
    "    return best_knn_model, grid_search_logreg.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bee78347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(labels, predictions):\n",
    "    \"\"\"\n",
    "    Given a list of actual labels and a list of predicted labels,\n",
    "    return a tuple (sensitivity, specificity).\n",
    "\n",
    "    Assume each label is either a 1 (positive) or 0 (negative).\n",
    "\n",
    "    `sensitivity` should be a floating-point value from 0 to 1\n",
    "    representing the \"true positive rate\": the proportion of\n",
    "    actual positive labels that were accurately identified.\n",
    "\n",
    "    `specificity` should be a floating-point value from 0 to 1\n",
    "    representing the \"true negative rate\": the proportion of\n",
    "    actual negative labels that were accurately identified.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return sensitivity, specificity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cc2a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Load data from spreadsheet and split into train and test sets\n",
    "    evidence, labels = load_data(\"shopping.csv\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        evidence, labels, test_size=TEST_SIZE, random_state=420, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Train model and make predictions\n",
    "    knn_model, logreg_model= train_model(X_train, y_train)\n",
    "    predictions_knn = knn_model.predict(X_test) # type: ignore\n",
    "    predictions_logreg = logreg_model.predict(X_test) \n",
    "\n",
    "      \n",
    "    sensitivity, specificity = evaluate(y_test, predictions_knn)\n",
    "    sensitivity_logreg, specificity_logreg = evaluate(y_test, predictions_logreg)\n",
    "\n",
    "    print(\"K-Nearest Neighbors Results:\")\n",
    "    print(f\"Correct: {(y_test == predictions_knn).sum()}\")\n",
    "    print(f\"Incorrect: {(y_test != predictions_knn).sum()}\")\n",
    "    print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
    "    print(f\"True Negative Rate: {100 * specificity:.2f}%\")\n",
    "\n",
    "\n",
    "    print(\"\\nLogistic Regression Results:\")\n",
    "    print(f\"Correct: {(y_test == predictions_logreg).sum()}\")\n",
    "    print(f\"Incorrect: {(y_test != predictions_logreg).sum()}\")\n",
    "    print(f\"True Positive Rate: {100 * sensitivity_logreg:.2f}%\")\n",
    "    print(f\"True Negative Rate: {100 * specificity_logreg:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f329055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for KNN: 0.3 (CV score: 0.9274)\n",
      "K-Nearest Neighbors Results:\n",
      "Correct: 4190\n",
      "Incorrect: 742\n",
      "True Positive Rate: 72.35%\n",
      "True Negative Rate: 87.26%\n",
      "\n",
      "Logistic Regression Results:\n",
      "Correct: 4316\n",
      "Incorrect: 616\n",
      "True Positive Rate: 72.48%\n",
      "True Negative Rate: 90.26%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b622b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9274405077738201), np.float64(0.8130901224871631)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
